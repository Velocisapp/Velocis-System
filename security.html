<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>VELOCISâ„¢ | AI SCANNER</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body { background: #000; color: #d4af37; font-family: 'Courier New', Courier, monospace; overflow: hidden; }
        .scanner-overlay { border: 2px solid rgba(212, 175, 55, 0.5); box-shadow: 0 0 20px rgba(212, 175, 55, 0.2); }
        .scan-line { height: 2px; background: #d4af37; box-shadow: 0 0 15px #d4af37; animation: scan 3s infinite linear; }
        @keyframes scan { 0% { top: 0; } 100% { top: 100%; } }
    </style>
</head>
<body class="flex flex-col items-center justify-between h-screen p-6">
    <div class="text-center">
        <h1 class="text-2xl font-bold tracking-widest uppercase">Security Gate</h1>
        <p class="text-xs opacity-60">AI DOCUMENT ANALYSIS ACTIVE</p>
    </div>

    <div class="relative w-full max-w-sm aspect-[3/4] scanner-overlay rounded-lg overflow-hidden">
        <video id="camera" class="w-full h-full object-cover grayscale brightness-125" autoplay playsinline></video>
        <div class="absolute inset-0 scan-line"></div>
    </div>

    <div id="status-box" class="w-full max-w-sm p-4 border border-[#d4af37] bg-black/80 rounded">
        <p id="output-text" class="text-xs uppercase leading-tight">Align Boarding Pass or Baggage Tag...</p>
    </div>

    <button id="scan-btn" onclick="captureAndAnalyze()" class="w-full max-w-sm py-4 bg-[#d4af37] text-black font-bold uppercase tracking-widest rounded-lg active:scale-95 transition-transform">
        Initialize Scan
    </button>

    <script>
        const video = document.getElementById('camera');
        const output = document.getElementById('output-text');

        // Access Camera
        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" } });
                video.srcObject = stream;
            } catch (err) {
                output.innerText = "CAMERA ACCESS DENIED: CHECK PERMISSIONS";
            }
        }

        async function captureAndAnalyze() {
            output.innerText = "ANALYZING MISSION DATA...";
            
            // 1. Capture Image Frame
            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            const base64Image = canvas.toDataURL('image/jpeg').split(',')[1];

            // 2. Send to Gemini AI
            try {
                // IMPORTANT: Vercel will inject your GEMINI_API_KEY here
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${window.env?.GEMINI_API_KEY || 'YOUR_TEST_KEY_HERE'}`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{
                            parts: [
                                { text: "Extract flight number, seat, gate, and destination from this image. Keep it brief for a mobile HUD." },
                                { inline_data: { mime_type: "image/jpeg", data: base64Image } }
                            ]
                        }]
                    })
                });

                const data = await response.json();
                const aiResult = data.candidates[0].content.parts[0].text;
                output.innerText = aiResult;
                
            } catch (err) {
                output.innerText = "AI HANDSHAKE FAILED: RETRYING...";
            }
        }

        startCamera();
    </script>
</body>
</html>